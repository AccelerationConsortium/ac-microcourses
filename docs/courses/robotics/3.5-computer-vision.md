
(3.5-orientation)=
# ðŸ§© 3.5 Computer Vision

```{contents}
:depth: 3
```

## ðŸ”° Tutorial

In this module, you will develop software to:
1. Demonstrate spatial referencing and ID lookup by using **OpenCV** and **AprilTags**
2. Use a motorized microscope and **OpenCV** to search for regions of interest (ROI) in a sample

### OpenCV

First, you will utilize **OpenCV**, a powerful computer vision library, to preprocess images, detect objects, and perform real-time computer vision tasks. **OpenCV** is widely used for various computer vision applications, including image filtering, object tracking, and edge detection.

#### Bill of Materials

- [OpenCV](https://pypi.org/project/opencv-python/) (for Python installation: `pip install opencv-python`)
- [AprilTag Python Library](https://pypi.org/project/apriltag/)
- [Motorized Microscope]
- [Raspberry Pi Camera Module](https://www.raspberrypi.org/products/camera-module-v2/)
- [USB-A to micro USB-B cable]

#### Demo

âœ… Read the [OpenCV Documentation](https://docs.opencv.org/4.x/)

âœ… Watch [Introduction to OpenCV](https://www.youtube.com/watch?v=oXlwWbU8l2o)

In this task, you will use **OpenCV** to perform image preprocessing, such as applying a Gaussian blur, detecting edges, and identifying regions of interest (ROI).

1. preprocess_image function:
Converts the image to grayscale
Applies Gaussian blur to reduce noise
Uses adaptive thresholding to create a binary image
2. find_roi function:
Preprocesses the image
Finds contours in the binary image
Sorts contours by area
Filters contours based on circularity and area to identify potential ROIs
Returns bounding rectangles for the identified ROIs
3. main function:
Loads an image
Finds ROIs using the find_roi function
Draws rectangles around the detected ROIs
Displays the result

```python
import cv2
import numpy as np

def preprocess_image(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Apply Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
    
    return thresh

def find_roi(image):
    # Preprocess the image
    processed = preprocess_image(image)
    
    # Find contours
    contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Sort contours by area (descending)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)
    
    rois = []
    for contour in contours[:5]:  # Consider top 5 largest contours
        # Calculate area and perimeter
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        
        # Calculate circularity
        circularity = 4 * np.pi * area / (perimeter * perimeter)
        
        # If the contour is sufficiently circular and large enough
        if circularity > 0.7 and area > 1000:
            x, y, w, h = cv2.boundingRect(contour)
            rois.append((x, y, w, h))
    
    return rois

def main():
    # Load an image
    image = cv2.imread('sample_image.jpg')
    if image is None:
        print("Error: Could not load image")
        return
    
    # Find ROIs
    rois = find_roi(image)
    
    # Draw ROIs on the original image
    for roi in rois:
        x, y, w, h = roi
        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    # Display the result
    cv2.imshow('ROI Detection', image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
```

This example assumes that ROIs are relatively circular and large. You may need to adjust the circularity and area thresholds based on your specific use case. Also, make sure to replace 'sample_image.jpg' with the path to your actual image file.

---

### AprilTags

Next, you will utilize **AprilTags**, a popular fiducial marker system for reliable and robust spatial referencing and object identification. AprilTags are often used in robotics for locating objects and navigating environments.

#### Bill of Materials

- [AprilTags Python Library](https://pypi.org/project/apriltag/)
- [AprilTags Documentation](https://april.eecs.umich.edu/software/apriltag.html)
- [Raspberry Pi Camera Module](https://www.raspberrypi.org/products/camera-module-v2/)
- [Motorized Microscope]
#### Demo

âœ… Watch [Vision Programming with AprilTags](https://youtu.be/TG9KAa2EGzQ)

The following code demonstrates how to use **AprilTags** for spatial referencing by detecting tags and performing ID lookup.
1. detect_apriltags function:
Converts the image to grayscale
Initializes the AprilTag detector
Detects AprilTags in the image
2. spatial_referencing function:
For each detected tag:
Estimates the tag's 3D pose
Extracts rotation and translation information
Draws the tag outline, center, and ID on the image
Prints spatial information (position and rotation)

```python
import cv2
import numpy as np
from pupil_apriltags import Detector

def detect_apriltags(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Initialize AprilTag detector
    at_detector = Detector(
        families="tag36h11",
        nthreads=1,
        quad_decimate=1.0,
        quad_sigma=0.0,
        refine_edges=1,
        decode_sharpening=0.25,
        debug=0
    )
    
    # Detect AprilTags
    tags = at_detector.detect(gray)
    
    return tags

def spatial_referencing(image, tags, tag_size=0.05):
    # Camera matrix (example values, replace with your camera's parameters)
    fx, fy, cx, cy = 1000, 1000, image.shape[1]/2, image.shape[0]/2
    camera_params = [fx, fy, cx, cy]
    
    for tag in tags:
        # Get tag pose
        pose, e0, e1 = tag.fit_pose(camera_params, tag_size)
        
        # Extract rotation and translation
        rotation_matrix = pose[:3, :3]
        translation_vector = pose[:3, 3]
        
        # Convert rotation matrix to Euler angles
        euler_angles = cv2.Rodrigues(rotation_matrix)[0].flatten()
        
        # Draw tag outline
        cv2.polylines(image, [np.int32(tag.corners)], True, (0, 255, 0), 2)
        
        # Draw tag center and ID
        center = tuple(map(int, tag.center))
        cv2.circle(image, center, 5, (0, 0, 255), -1)
        cv2.putText(image, str(tag.tag_id), (center[0] - 10, center[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # Print spatial information
        print(f"Tag ID: {tag.tag_id}")
        print(f"Position: X={translation_vector[0]:.2f}, Y={translation_vector[1]:.2f}, Z={translation_vector[2]:.2f}")
        print(f"Rotation: Roll={np.degrees(euler_angles[0]):.2f}, Pitch={np.degrees(euler_angles[1]):.2f}, Yaw={np.degrees(euler_angles[2]):.2f}")
        print("---")
    
    return image

def main():
    # Initialize camera
    cap = cv2.VideoCapture(0)  # Use 0 for default camera, adjust if needed
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Failed to capture image")
            break
        
        # Detect AprilTags
        tags = detect_apriltags(frame)
        
        # Perform spatial referencing
        frame_with_tags = spatial_referencing(frame, tags)
        
        # Display the result
        cv2.imshow('AprilTag Spatial Referencing', frame_with_tags)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
```

This example assumes you have a camera connected and AprilTags in view. You'll need to adjust the camera matrix parameters (fx, fy, cx, cy) to match your specific camera's calibration. Also, make sure to set the correct tag_size in meters.

---

### Motorized Microscope and OpenCV

After detecting regions of interest (ROI) using **OpenCV** and **AprilTags**, you will integrate a motorized microscope. The microscope will move automatically based on the ROI found in the image, providing fine control and automation for analyzing samples.

#### Demo

âœ… Watch [Controlling a Motorized Microscope](https://youtu.be/fHZSsAKThW4)

This example code combines OpenCV image processing techniques with simulated microscope functionality to implement automated monitoring of yeast growth. The main features include:
1. Image preprocessing: Using Gaussian blur and adaptive thresholding to enhance image quality.
2. Yeast cell detection: Using contour detection methods to identify potential yeast cells.
3. Microscope scanning: Utilizing the simulated microscope to scan an area and obtain multiple images.
4. Growth analysis: Calculating the number of detected cells and estimating the growth rate.
5. Visualization: Marking detected cells on each scanned image and displaying the results.

This program performs periodic (hourly) scanning and analysis to continuously monitor yeast growth. You can adjust the scanning interval, cell detection parameters, and other settings according to your specific requirements.

```python
import cv2
import numpy as np
from microscope_demo_client import MicroscopeDemo
from my_secrets import (
    HIVEMQ_HOST,
    HIVEMQ_PASSWORD,
    HIVEMQ_PORT,
    HIVEMQ_USERNAME,
    MICROSCOPE_NAME,
)
import time
from PIL import Image
import io

# Initialize simulated microscope
microscope = MicroscopeDemo(
    HIVEMQ_HOST, HIVEMQ_PORT, HIVEMQ_USERNAME, HIVEMQ_PASSWORD, MICROSCOPE_NAME
)

def preprocess_image(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Apply Gaussian blur
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
    return thresh

def detect_yeast_cells(image):
    # Preprocess the image
    processed = preprocess_image(image)
    
    # Find contours
    contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Filter and analyze contours
    cells = []
    for contour in contours:
        area = cv2.contourArea(contour)
        if 50 < area < 500:  # Assume yeast cells are within this area range
            cells.append(contour)
    
    return cells

def analyze_growth(previous_count, current_count):
    growth_rate = (current_count - previous_count) / previous_count * 100 if previous_count > 0 else 0
    return growth_rate

def microscope_scan_and_analyze():
    print("Starting area scan...")
    scan_images = microscope.scan([2000, 2000], [-2000, -2000])
    
    total_cells = 0
    for i, img_data in enumerate(scan_images):
        # Convert image data to OpenCV format
        img = Image.open(io.BytesIO(img_data))
        img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        
        # Detect yeast cells
        cells = detect_yeast_cells(img_cv)
        total_cells += len(cells)
        
        # Draw detection results
        img_with_cells = img_cv.copy()
        cv2.drawContours(img_with_cells, cells, -1, (0, 255, 0), 2)
        
        # Display results
        cv2.imshow(f'Scan {i+1}/{len(scan_images)}', img_with_cells)
        cv2.waitKey(1000)  # Display for 1 second
        
        print(f"Scan image {i+1}/{len(scan_images)}: Detected {len(cells)} yeast cells")
    
    cv2.destroyAllWindows()
    return total_cells

def main():
    try:
        previous_cell_count = 0
        while True:
            # Move microscope to initial position and focus
            microscope.move(0, 0)
            microscope.focus()
            
            # Scan and analyze
            current_cell_count = microscope_scan_and_analyze()
            
            # Calculate growth rate
            growth_rate = analyze_growth(previous_cell_count, current_cell_count)
            
            print(f"Total detected yeast cells: {current_cell_count}")
            print(f"Growth rate: {growth_rate:.2f}%")
            
            previous_cell_count = current_cell_count
            
            # Wait for a period before scanning again
            time.sleep(3600)  # Wait for 1 hour
    
    except KeyboardInterrupt:
        print("Monitoring stopped")
    finally:
        microscope.end_connection()

if __name__ == "__main__":
    main()
```

You can integrate the motorized microscope with your **OpenCV** detection pipeline, enabling real-time analysis and precise control.

---

## ðŸš€ Quiz

::::{tab-set}
:sync-group: category

:::{tab-item} Sp/Su 2024
:sync: sp2024

[Quiz URL]
:::

::::

---

## ðŸ“„ Assignment

Create a script that uses **OpenCV** and **AprilTags** to detect regions of interest in a sample and control a motorized microscope to move to those regions.

âœ… First, preprocess the sample image using **OpenCV** (apply filters and detect edges).
âœ… Then, detect and extract **AprilTags** for spatial referencing.
âœ… Finally, automate the movement of the motorized microscope to the detected regions of interest.

Example tasks:
1. Write a script to process an image and identify ROIs using **OpenCV**.
2. Detect **AprilTags** and use the tag ID for tracking and referencing.
3. Integrate a motorized microscope to search and focus on regions of interest.

