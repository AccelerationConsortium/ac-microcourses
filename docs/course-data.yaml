hello-world:
  # course_title: "Building a 'Hello World' for self-driving labs"
  course_title: "Introduction to AI for Discovery using Self-driving Labs"
  course_emoji: "💡"
  description: "Self-driving laboratories (SDLs) incorporate AI and automation into scientific laboratories to speed up the discovery of new materials for applications such as clean energy and cancer drugs. Discover the essential principles of SDLs by building a 'Hello World' SDL from scratch. In this asynchronous, remote course, you will build a self-driving color matcher using dimmable LEDs and a light sensor. This introduction will help you implement hardware/software communication, database integration, microcontroller programming, and Bayesian optimization. Each of these are important components of an SDL, and you will get a taste of these in the course modules. The course will conclude with an expansion of the demo to the research-relevant task of continuously logging temperature, humidity, pressure, light, and accelerometer data."
  media_command: "![](./images/clslab-light.gif)"
  media_caption: "Animated schematic diagram of the 'Hello World' demo: A microcontroller controls the LEDs and reads sensor data. The difference between the target color and the measured color is fed into an adaptive experimentation algorithm, and the process repeats itself."
  recommended_prerequisites: |

    ```{include} ./hardware-note.md
    ```

    For participants to complete this course within the expected timeframe (approx. 20 hours), beginner proficiency in Python programming is recommended.

  learning_outcomes:
    - "Describe key terms and principles of self-driving labs"
    - "Send commands and receive sensor data over WiFi using standard frameworks such as MQTT"
    - "Store experiment configurations and results in databases such as MongoDB"
    - "Implement software on a microcontroller such as Raspberry Pi Pico W to adjust device power and read sensor data"
    - "Adapt a Bayesian optimization script from packages such as the Ax Platform to iteratively suggest new colors to try"
    - "Implement workflow orchestration for a color experiment using packages such as Covalent"
    - "Integrate the individual SDL components to finalize the 'Hello World' demo"
    - "Modify the system to record temperature, humidity, barometric pressure, and accelerometer measurements"
  competencies_skills:
    - "Basic self-driving lab literacy"
    - "Database management"
    - "Workflow orchestration"
    - "Bayesian optimization"
    - "Microcontrollers and sensors"
    - "Hardware/software communication"
  orientation:
    - "Course overview"
    - "Certificate overview" # TODO: Where does Alan's YouTube video fit in, if at all? Certificate overview perhaps?
  module_note: "The orientation modules are intended to be completed in under one hour in total. The modules after are intended to take approximately 2-3 hours each, assuming that the recommended prerequisites from above have been met."
  modules:
    - module_name: "0.1/0.2 Orientation"
      topics:
        - "Git"
        - "GitHub"
        - "Version control"
        - "GitHub Classroom"
        - "Codespaces"
      learning_outcomes:
        - "Describe the purpose of Git and GitHub"
        - "Create a GitHub account and a repository"
        - "Commit, push, and pull changes"
        - "Run a unit test and fix a simple Python function"
        - "Define continuous integration"
      assessments:
        - "Quiz: Enter your GitHub classroom ID and your GitHub username"
        - "Quiz: Match terms with definitions"
        - "Pytest: Update a Python file to return the correct string"
        - "Quiz: Self-report the overall GitHub Classroom score"
    - module_name: "1. Running the SDL demo"
      topics:
        - "Database management"
        - "Bayesian optimization"
        - "Microcontrollers"
      learning_outcomes:
        - "Describe key terms and principles of self-driving labs"
        - "Preview an end-to-end self-driving lab"
        - "Upload software to a microcontroller"
      tutorial:
        - "Video: build instructions for the SDL demo https://youtu.be/D54yfxRSY6s?si=fjS6yxr-mKb3yBEp"
        - "Building a hello world for self-driving labs: https://doi.org/10.1016/j.xpro.2023.102329"
        - "Additional resource: Accelerate 2022 talk https://youtu.be/LNkRjByzeZg?si=FmyAMy0vELeUOae5"
        - "Additional resource: What is a minimal working example for a self-driving laboratory? perspective paper https://doi.org/10.1016/j.matt.2022.11.007 (include a static copy and/or a link to the postprint: https://github.com/sparks-baird/self-driving-lab-demo/blob/main/reports/self_driving_optics_demo-rev1.pdf)"
      assessments:
        # - "Quiz: Check for matched terms with definitions"
        - "Quiz: Match the term to the specific platform used in CLSLab:Light" # demonstrate reading of manuscript
        # - "Pytest: Check that source code from a zip file is copy-pasted into a certain file"
        # - "Pytest: Check that a 'test' demo database entry exists that contains their course identifier"
        - "Pytest: Check for a test entry with their course identifier from the public database"
    - module_name: "2. Blink and Read"
      topics:
        - "Microcontrollers"
        - "MicroPython"
      learning_outcomes:
        - "Write MicroPython scripts"
        - "Use a microcontroller"
      tutorial:
        - "Blink LED on Pico W tutorial (Getting started with the Pico W or similar)"
        - "NeoPixel tutorial"
        - "Maker Pi Pico neopixel tutorial"
        - "AS7341 Adafruit tutorial"
        - "main.py from tutorial https://github.com/sparks-baird/self-driving-lab-demo/blob/2f4bf8c27cf80776821306ce443244d11fae8968/src/public_mqtt_sdl_demo/main.py"
      assessments:
        # - "Quiz: Enter the name of the file (including extension) that needs to be uploaded to the microcontroller"
        - "Quiz: Enter the names of the MicroPython module and class that need to be imported to control the LED (machine.Pin, neopixel.NeoPixel)"
        - "Quiz: Enter the name of the MicroPython module and class that lets you interface with the light sensor (as7341_sensor.Sensor)"
        - "Pytest: Verify that a filled in function (that uses a dummy class for machine.Pin) returns the expected command"
        - "Pytest: Verify that a filled in function (that uses a dummy class for AS7341) returns the expected data"
        # - "Quiz & ungraded pytest: Check that some command line output (that users copy-pasted from Thonny terminal) matches the answer key for a script that blinks an LED"
        # - "Quiz & ungraded pytest: Check that some command line output (that users copy-pasted from Thonny terminal) matches the answer key for a script that reads the sensor data"
    - module_name: "3. Bayesian optimization"
      topics:
        - "Design of experiments"
        - "Bayesian optimization"
        - "Data visualization"
      learning_outcomes:
        - "Adapt a Bayesian optimization script to perform color-matching"
        - "Compare Bayesian optimization with other search methods"
        - "Visualize optimization efficiency"
      tutorial:
        - "Video: A gentle introduction to Bayesian optimization | https://youtu.be/IVaWl2tL06c?si=P5dQFs4pX5TxsYxS"
        - "grid vs. random vs. Bayes (sort of from scratch) tutorial: https://towardsdatascience.com/grid-search-vs-random-search-vs-bayesian-optimization-2e68f57c3c46"
        - "Video: Bayes rule by 3Blue1Brown | https://youtu.be/HZGCoVF3YvM?si=Gfoi-0sRvxqsTW2u"
        - "combining content from random search for a self-driving lab https://github.com/sparks-baird/self-driving-lab-demo/blob/6c0b5f63b37ad2c24dea1a51bab498ac2cc37853/notebooks/2.0-random-search.ipynb grid search and BO https://github.com/sparks-baird/self-driving-lab-demo/blob/567184a073143f129b2ec72607ef0709222e51d4/notebooks/2.3-bayesian-optimization.ipynb and running comparisons of all three https://github.com/sparks-baird/self-driving-lab-demo/blob/112e7e6bfa69c11d61dcbbc4e72a704be0adb87b/notebooks/3.1-random-vs-grid-vs-bayesian.ipynb"
      assessments:
        - "Quiz: Match terms with definitions (summarized definitions from GPT4). Random number generator seed, grid search, random search, Sobol sampling, Latin Hypercube, Quasi-random, Bayesian optimization, Acquisition function, Exploration, Exploitation, Surrogate model, Constraint, Parameter, Expected improvement, Gaussian Process, Curse of dimensionality"
        - "Quiz: Ask a simple question about grid search (what are the datapoints for a 1D grid search from 0 to 1 with 3 points)"
        - "Quiz: Identify the number of grid points in 1D, 2D, and 3D with 3 points along each dimension"
        - "Quiz: Rank the typical efficiency of grid search vs. random search vs. quasi-random vs. Bayesian optimization"
        - "Quiz: Enter a random number generated by numpy according to directions in <URL> using a seed of 10 to N decimal points"
        # NOTE: could be paired with Canvas quiz, but difficult to keep synced
        # NOTE: provide a dummy class for the light-mixing demo
        - "Pytest: Verify that the filled in code for grid search with a specific set of seeds and a fixed Ax version reaches a particular outcome (i.e., verify that two floats match) for Branin function"
        - "Pytest: Verify that the filled in code for random search with a specific set of seeds reaches a particular outcome (i.e., match the numbers) for Branin function."
        - "Pytest: Verify that the filled in code for Bayesian optimization with a specific set of seeds and a fixed Ax version reaches a particular outcome (i.e., match the numbers)  for Branin function."
        - "Pytest: Verify that the data to be placed in a matplotlib figure for 'best result so far' vs. iteration number matches the answer key for a specific set of seeds for Branin function"
    - module_name: "4. Device communication"
      topics:
        - "MQTT"
        - "Broker/client"
      learning_outcomes:
        - "Send commands to a microcontroller"
        - "Receive sensor data from a microcontroller"
      tutorial:
        - "Video: What is MQTT? (or some equivalent, keep it to ~5 minutes maybe? Could be part 1 of HiveMQ MQTT essentials https://www.youtube.com/playlist?list=PLRkdoPznE1EMXLW6XoYLGd4uUaB6wB0wd)"
        - "Create a HiveMQ account and broker"
        - "Paho MQTT Python client: http://www.steves-internet-guide.com/receiving-messages-mqtt-python-client/ (specifically the part about Queue)"
        - "Google Colab Link to a Paho MQTT client ?"
        - "Send a toggle command to the onboard LED and receive the temperature"
      assessments:
        - "Quiz: Match terms with definitions (MQTT, Broker, Client, Paho MQTT, HiveMQ, micropython-mqtt, First-in first-out (FIFO) queue, Publish, Subscribe, callback, host, JSON, while loop, payload, quality of service)"
        - "Quiz: Pair the QOS level with the description"
        - "Quiz: Multiple fill in the blank: Publish the `LED command` to the `LED topic`, `` subscribes to `` on the `` topic. Etc."
        - "Pytest: Check that users added personal HiveMQ credentials as repository secrets, and that they're not the sgbaird ones"
        # - "Pytest: Verify the broker is working by running it with the pre-built CLSLab:Light demo (reuse the 'running the demo' pytest)."
        - "Pytest: Verify that a message can be sent using the HiveMQ secrets that were supplied, and that it's not the one provided publicly by me. Have it be the sending and receiving of the onboard LED command and the onboard temperature, respectively."
        - "Pytest: Verify that a user-implemented CLSLab:Light message gets sent/received properly (i.e., adapted optimization pytest from 'running the demo' or just a simple message)"
    - module_name: "5. Logging data"
      topics:
        - "MongoDB"
        - "Database management"
      learning_outcomes:
        - "Set up a MongoDB account and database"
        - "Upload data directly from microcontroller"
      assessments:
        - "Quiz: Match terms with definitions"
        - "Quiz: Check for a match between a pre-uploaded (by me) specific database entry and the user input"
        - "Pytest: Check that users added personal MongoDB credentials as repository secrets"
        - "Pytest: Verify that an entry can be added using the MongoDB secrets and that it's not the one provided publicly by me"
    - module_name: "6. Module integration"
      topics:
        - "Systems design"
      learning_outcomes:
        - "Connect the pieces to complete the SDL demo"
      assessments:
        - "Quiz: left-middle-right matching statements. E.g., <the Pico W> sends data using the <MQTT> protocol to the <HiveMQ> broker. The <Python client> sends commands using the <MQTT> protocol to the <Pico W> client. The <Pico W> sends data using the <MongoDB> protocol to the <MongoDB> database. The <Ax Platform> sends suggested next experiments to the <Python client> and receives new data from the <Python client>."
        - "Pytest: Programatically access their (up-and-running) machine and check that the RMSE for a seeded Bayesian optimization search is below some threshold"
    - module_name: "7. Lab sensor system"
      topics:
        - "Environmental sensors"
      learning_outcomes:
        - "Continuously log temperature, humidity, vibration, etc."
      assessments:
        - "Quiz: match the data type with the name of each sensor (e.g., AS7341)"
        - "Pytest: Programatically access the (up-and-running) machine and validate the schema of the data"
  course_assessments_and_grading_schema: "Each module will contain the following:<br><br><ul><li>🧭 A guided notebook tutorial (ungraded)</li><li>📓 A knowledge check (graded, 5 points)</li><li>🛠️ A mini project (graded, 10 points)</li></ul>"

data-science:
  course_title: "AI and Materials Databases for Self-Driving Labs"
  course_emoji: "📊"
  description: "Unleash the power of data science in the realm of self-driving laboratories. This remote, asynchronous course empowers you to apply data science concepts to materials discovery tasks. You'll create Bayesian optimization scripts using the Ax Platform, explore advanced optimization topics, and use the Honegumi template generator to create an advanced optimization setup for a materials discovery task. Additionally, you'll learn to share your findings by uploading datasets to FigShare, creating benchmark models with scikit-learn, and hosting models on HuggingFace."
  media_command: "![](./images/ax-repo/bo_1d_opt.gif)"
  media_caption: "*Animation of 1D Bayesian Optimization: A Gaussian Process surrogate model can be used with an acquisition function to seamlessly transition from exploration to optimization in noisy settings. Source: [https://ax.dev/docs/bayesopt.html](https://ax.dev/docs/bayesopt.html)*"
  recommended_prerequisites: "The **recommended prerequisite** for this course is {{ hello-world }}"
  learning_outcomes:
    - "Describe a materials discovery task using data science language and concepts"
    - "Adapt a Bayesian optimization script to find an optimal chocolate chip cookie recipe"
    - "Judiciously choose an advanced optimization setup that matches a materials discovery task"
    - "Programatically upload a completed dataset to Figshare, create a benchmark model, and host it on HuggingFace"
  competencies_skills:
    - "Data science literacy"
    - "Bayesian optimization"
    - "Advanced Bayesian optimization"
    - "Workflow orchestration"
    - "Benchmarking"
  module_note: "Each module is intended to take approximately 2-3 hours, assuming that the recommended prerequisites have been met."
  modules:
    - module_name: "Gentle intro to Bayesian optimization"
      topics:
        - "Design of experiments"
        - "Quasi-random search methods"
        - "Bayesian optimization"
        - "Expected improvement (EI)"
        - "Ax Platform"
        - "Honegumi template generator"
      learning_outcomes:
        - "Describe a materials discovery task using data science language and concepts"
        - "Adapt a Bayesian optimization script to find an optimal chocolate chip cookie recipe"
      assessments:
        - "Quiz: Match advanced opt terms with definitions"
        - "Quiz: Check all that apply (provide text description of a materials discovery task)"
        - "Quiz: Check all that apply (provide text description of a materials discovery task) (new Q)"
        - "Quiz: Enter some optimized number of score from the optimal chocolate chip cookie recipe based on fixed seeds"
        - "Pytest: assert required modules are present"
        - "Pytest: assert the the Ax object is instantiated correctly"
        - "Pytest: assert that the best parameters are correct for a fixed seed"
    - module_name: "Multi-objective optimization"
      topics:
        - "Pareto fronts"
        - "Hypervolume"
        - "EHVI"
        - "Objective thresholds"
      learning_outcomes:
        - "Explain the significance of a Pareto front"
        - "Compare simple scalarization with expected hypervolume improvement"
        - "Explore the effect of setting objective thresholds"
      assessments:
        - "Quiz: Match terms with definitions"
        - "Pytest: check for a match of Pareto front data for a fixed seed"
        - "Pytest: Verify correct imports"
        - "Pytest: Verify that a Pareto frontier plot is generated using the right function (e.g., the output is a plotly figure)"
        - "Pytest: Verify syntax for setting objective thresholds"
    - module_name: "Constrained optimization"
      topics:
        - "Linear constraints"
        - "Nonlinear constraints"
        - "Compositional constraints"
        - "Order constraints"
      learning_outcomes:
        - "Provide examples of materials discovery tasks with constraints"
        - "Adapt a Bayesian optimization script to include constraints"
      assessments:
        - "Quiz: Match terms with examples"
        - "Pytest: Verify that certain parameter sets pass or fail the constraint (i.e., check in the vicinity of the constraint)"
        - "Quiz: Report the optimized value for a given seed"
    - module_name: "High-dimensional optimization"
      topics:
        - "Curse of dimensionality"
        - "SAASBO"
      learning_outcomes:
        - "Explain the curse of dimensionality"
        - "Compare the efficiency of expected improvement and SAASBO as a function of dimensionality"
      assessments:
        - "Quiz: Match terms with definitions (SAASBO, curse of dimensionality, discrepancy)"
        - "Quiz: Report the final efficiencies for EI and SAASBO for a given seed for three different dimensionalities"
        - "Pytest: Verify that the optimization history matches for a fixed seed"
        - "Pytest: Verify that the optimization traces are correct by checking the figure return type and accessing the raw data"
    - module_name: "Featurization"
      topics:
        - "Domain knowledge integration"
        - "Contextual variables"
        - "Predefined candidates"
      learning_outcomes:
        - "Explain the advantages and disadvantages of featurization"
        - "Adapt a Bayesian optimization script to use predefined candidates with featurization"
        - "Adapt a Bayesian optimization script to use contextual variables"
      assessments:
        - "Quiz: Match terms with definitions"
        - "Quiz: Select the cases that have contextual variables (i.e., variables not directly controlled by user, but that provide contextual information)"
        - "Quiz: Check all that apply (provide text description of a materials discovery task)"
        - "Quiz: Input the final optimized values for three cases: no featurization, featurization (known by me) that performs better, featurization (known by me) that performs worse with fixed seeds"
        - "Pytest: Verify that the optimization history matches for a fixed seed"
        - "Pytest: Verify that the optimization traces are correct by checking the figure return type and accessing the raw data"
        - "Quiz: Input the final optimized values for three cases: without a contextual variable, with an important contextual variable, and with a red-herring contextual variable (could use one of the matsci-opt benchmarks or Vickers hardness, etc.)."
        - "Compare the optimization efficiency, runtime, and resource utilization for three cases: small number of predefined candidates, large number of predefined candidates, and continuous optimization"
    - module_name: "Multi-fidelity and multi-task optimization"
      topics:
        - "Cost-fidelity tradeoffs"
        - "Knowledge gradient"
      learning_outcomes:
        - "Explain the effect of cost-fidelity tradeoffs on optimization"
        - "Explain when to use multi-fidelity vs. multi-task optimization"
        - "Assess the efficiency of expected improvement at fixed fidelities vs. knowledge gradient"
        - "Adapt a Bayesian optimization script to use a knowledge gradient"
      assessments:
        - "Quiz: Match terms with definitions"
        - "Quiz: Select the cases that have multiple fidelities (i.e., variables where as cost increases, fidelity is expected to increase)"
        - "Quiz: Categorize several cases as multi-fidelity vs. multi-task per guidelines in https://github.com/facebook/Ax/issues/1038"
        - "Quiz: Input the final optimized values after a certain budget is used up for the following cases: fidelity fixed to lowest, fidelity fixed to middle, fidelity fixed to highest, variable fidelity via knowledge gradient"
    - module_name: "Benchmark datasets and models"
      topics:
        - "Benchmarks"
        - "Surrogate models"
        - "Random forest regression"
        - "FAIR data"
        - "Model deployment"
        - "APIs"
      learning_outcomes:
        - "Explain the effect of noise on benchmarking tasks"
        - "Programatically upload a completed dataset to Figshare"
        - "Create a benchmark model with scikit-learn"
        - "Host a model on HuggingFace"
      assessments:
        - "Quiz: Match terms with definitions (homoskedastic noise, heteroskedastic noise, standard error metric, standard deviation, API, benchmark, model, FAIR data, surrogate model, random forest regression)"
        - "Quiz: Read the matsci-opt benchmarks paper and provide a DOI link to the figshare dataset"
        - "Quiz: Provide a link to the matsci-opt GitHub repo"
        - "Quiz: Provide a link to the HuggingFace model (TBD)"
        - "Pytest: Download a user's dataset via a DOI link and verify that the data is of the correct type and follows the correct schema"
        - "Pytest: Verify that the HuggingFace model can be accessed to return results"
  course_assessments_and_grading_schema: "{{ courses.hello-world.course_assessments_and_grading_schema }}"

robotics:
  course_title: "Autonomous Systems for Self-Driving Labs"
  course_emoji: "🦾"
  description: "Embark on a journey into the world of robotics and automation for self-driving laboratories. This asynchronous, remote course equips you with the skills to control peristaltic pumps, linear actuators, automated liquid handlers, and solid dispensers using a Pico W microcontroller, a motor driver, and the Covalent workflow orchestration package. You'll also learn to control mobile cobots using the Robot Operating System (ROS) framework and to perform spatial referencing and ID recognition via AprilTags and OpenCV. The course will conclude with a solid sample transfer workflow using Covalent, ROS, AprilTags, OpenCV, and a multi-axis robot."
  media_command: "<video width='100%' controls autoplay muted><source src='./../../_static/ac-website/robot-loop.mp4' type='video/mp4'>Your browser does not support the video tag.</video>"
  media_caption: "Self-driving lab robotic platforms. 1. ADA at the University of British Columbia (C. Berlinguette, J. Hein, A. Aspuru-Guzik); 2. Artificial Chemist (M. Abolhasani, NC State University); 3. Robotically reconfigurable flow chemistry platform (C. Coley, MIT); 4. Chemputer (L. Cronin, University of Glasgow); 5. Mobile robot chemist (A. Cooper, University of Liverpool). Source: [https://acceleration.utoronto.ca/maps](https://acceleration.utoronto.ca/maps)"
  recommended_prerequisites: "The **recommended prerequisite** for this course is {{ hello-world }}"
  learning_outcomes:
    - "Implement software to control a peristaltic pump via a microcontroller and a motor driver"
    - "Build the \"Digital Pipette\" and implement software to control the linear actuator"
    - "Perform liquid transfer between vials with an automated liquid handler (Jubilee or Opentrons)"
    - "Demonstrate control of a mobile cobot using the robot operating system (ROS) framework"
    - "Demonstrate spatial referencing and ID lookup by using OpenCV and AprilTags"
    - "Use ROS, AprilTags, and a multi-axis robot to perform solid sample transfer"
  competencies_skills:
    - "Motor drivers"
    - "Automated liquid handlers"
    - "Robotic control"
    - "Computer vision"
    - "Automated solid handlers"
  module_note: "Each module is intended to take approximately 2-3 hours, assuming that the recommended prerequisites have been met."
  modules:
    - module_name: "Controlling pumps and pipettes"
      topics:
        - "Workflow orchestration"
        - "Microcontrollers"
        - "Peristaltic pumps"
        - "Linear actuators"
        - "Motor drivers"
      learning_outcomes:
        - "Implement software to control a peristaltic pump via a microcontroller and a motor driver"
        - "Build the \"Digital Pipette\" and implement software to control the linear actuator"
    - module_name: "Automated liquid handlers"
      topics:
        - "Workflow orchestration"
        - "Jubilee"
        - "Opentrons"
      learning_outcomes:
        - "Perform liquid transfer between vials with an automated liquid handler (Jubilee or Opentrons)"
    - module_name: "Mobile robotics"
      topics:
        - "ROS"
      learning_outcomes:
        - "Demonstrate control of a mobile cobot using the Robot Operating System (ROS)"
    - module_name: "Computer vision"
      topics:
        - "OpenCV"
        - "AprilTags"
      learning_outcomes:
        - "Demonstrate spatial referencing and ID lookup by using OpenCV and AprilTags"
    - module_name: "Solid sample transfer"
      topics:
        - "Workflow orchestration"
        - "ROS"
        - "AprilTags"
        - "Multi-axis robotics"
      learning_outcomes:
        - "Use ROS, AprilTags, and a multi-axis robot to perform solid sample transfer"
  course_assessments_and_grading_schema: "{{ courses.hello-world.course_assessments_and_grading_schema }}"

"software-dev":
  course_title: "Software development for self-driving labs"
  course_emoji: "👩‍💻"
  description: "Elevate your software development skills in the context of self-driving laboratories. This asynchronous, remote course introduces software development concepts and best practices and productivity tools such as integrated development environments (IDEs) with VS Code, unit testing with pytest, continuous integration via GitHub actions, and documentation creation using Sphinx and Read the Docs. You'll also learn to deploy materials discovery campaigns on cloud servers or dedicated hardware and run offline simulations using cloud hosting."
  media_command: ""
  media_caption: ""
  recommended_prerequisites: "The **recommended prerequisite** for this course is {{ hello-world }}"
  learning_outcomes:
    - "List software development best practices and corresponding benefits"
    - "Identify productivity tools for developers that increase efficiency"
    - "Write unit tests using tools such as pytest"
    - "Create Python documentation using sphinx and rtd"
    - "Implement continuous integration (CI) using tools such as GitHub actions"
    - "Create a project template using PyScaffold"
    - "Launch a cloud server or server on dedicated local hardware that runs a materials discovery campaign"
    - "Run an offline simulation using cloud hosting"
  competencies_skills:
    - "Software development literacy"
    - "Unit testing"
    - "Documentation"
    - "Compute hardware"
    - "Cloud computing"
  module_note: "Each module is intended to take approximately 2-3 hours, assuming that the recommended prerequisites have been met."
  modules:
    - module_name: "Setting up VS Code"
      topics:
        - "IDEs"
        - "Miniconda"
        - "VS Code extensions"
      learning_outcomes:
        - "Set up VS Code"
        - "Install Miniconda"
        - "Install VS Code extensions"
    - module_name: "Debugging in VS Code"
      topics:
        - "Print statements"
        - "Setting breakpoints"
        - "Inspecting variables"
        - "Stepping through code"
        - "Debug console"
        - "Debug configurations"
      learning_outcomes:
        - "Use print statements to debug code"
        - "Set breakpoints"
        - "Inspect variables"
        - "Step through code"
        - "Use the debug console"
        - "Set up debug configurations"
    - module_name: "Unit testing"
      topics:
        - "pytest"
        - "Test result interpretation"
        - "Debugging"
        - "Test-driven development"
      learning_outcomes:
        - "Explain the purpose of unit tests"
        - "Write unit tests for the light-mixing demo"
        - "Run and interpret unit tests to fix code"
        - "Explain test-driven development"
    - module_name: "Automated documentation"
      topics:
        - "Markdown"
        - "Documentation as code"
        - "Sphinx"
        - "Readthedocs"
      learning_outcomes:
        - "Write documentation in Markdown"
        - "Explain what documentation as code means"
        - "Set up a readthedocs account and publish a readthedocs page"
    - module_name: "Continuous integration (CI)"
      topics:
        - "Continuous integration"
        - "GitHub actions"
        - "Unit tests"
        - "Documentation"
      learning_outcomes:
        - "Explain the purpose of continuous integration"
        - "Set up a GitHub actions workflow"
        - "Run unit tests and documentation builds on GitHub actions"
    - module_name: "Project templates"
      topics:
        - "PyScaffold"
        - "Cookiecutter"
        - "Project initialization"
        - "Project adaptation"
      learning_outcomes:
        - "Create a project template using PyScaffold"
        - "Add project content"
    - module_name: "Launching a free cloud server"
      topics:
        - "Serverless computing"
        - "PythonAnywhere"
        - "Deploying Applications"
      learning_outcomes:
        - "Launch a free cloud server"
        - "Deploy a materials discovery campaign on a cloud server"
    - module_name: "On-demand cloud simulations"
      topics:
        - "Cloud computing"
        - "Setting up an AWS account"
        - "AWS Lambda"
      learning_outcomes:
        - "Run an on-demand cloud simulation"
        - "Integrate a cloud simulation into a materials discovery campaign"
  course_assessments_and_grading_schema: "{{ courses.hello-world.course_assessments_and_grading_schema }}"

capstone:
  course_title: "AC Training Lab Design Project"
  course_emoji: "🏢"
  description: "Turn your self-driving lab expertise into a real-world project. During this course, you will propose, design, and build a self-driving laboratory at the AC training lab equipped with education- and research-grade equipment including liquid handlers, solid dispensers, Cartesian-axis systems, and mobile robotic arms. Prior to arrival, you'll create schematic figures, write white papers, and present your proposals to a team of scientists. During a week-long in-person experience, you'll implement your proposal and document your progress. After the visit, you will share your designs, data, and documentation to contribute to the public knowledge base."
  media_command: ""
  media_caption: ""
  recommended_prerequisites: "💡 {{ hello-world }}<br>📈 {{ data-science }}<br>🦾 {{ robotics }}<br>🧑‍💻 {{ software-dev }}"
  learning_outcomes:
    - "Propose a self-driving lab via a schematic figure"
    - "Write a white paper for the self-driving laboratory"
    - "Present the proposal to a team of scientists"
    - "Design and execute a capstone project at the AC Training Lab"
    - "Provide a project update with proposed next steps"
    - "Share the designs, data, and documentation publicly"
  competencies_skills:
    - "Scientific communication"
    - "Systems design"
    - "Dissemination"
    - "Interdisciplinary teamwork"
  module_note: "This course is expected to take approximately 40 hours to complete."
  modules:
    - module_name: "Project proposal"
      topics:
        - "Figures"
        - "White papers"
        - "Presentations"
      learning_outcomes:
        - "Propose a self-driving lab via a schematic figure"
        - "Write a white paper for the self-driving laboratory"
        - "Present the proposal to a team of scientists"
    - module_name: "Design and execution"
      topics:
        - "SDL design"
        - "Implementation"
        - "Documentation"
      learning_outcomes:
        - "Design and execute the project at the AC training lab"
        - "Provide a project update with proposed next steps"
    - module_name: "Dissemination"
      topics:
        - "Project update"
        - "Knowledge sharing"
        - "Data and documentation"
      learning_outcomes:
        - "Share the designs, data, and documentation publicly"
  course_assessments_and_grading_schema: "Performance in this course is assessed via rubrics that evaluate the quality of the proposal, design/build, and stages. The proposal rubric evaluates the schematic figure, white paper, and presentation. The design rubric evaluates the design, implementation, and documentation. The build rubric evaluates the build, implementation, and documentation. Each module is worth 100 points."
